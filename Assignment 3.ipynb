{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>CSIS 452 - Applied Machine Learning</center>\n",
    "## Assignment 3 - due: 3/12/2020\n",
    "In this assignment you will experiment with linear regression and generalization concepts using attached decay-rate data set.  <p><i>Please ignore any <b>FutureWarnings</b> warnings when you run your code.</i></p>\n",
    "\n",
    "Enter your name as a comment in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Developer: Brady Lange\n",
    "\n",
    "Date: 02/19/2020\n",
    "\n",
    "Description: Temperature decay rate analysis with Linear Regression and Generalization.\n",
    "\n",
    "Course: Applied Machine Learning (CSIS 452)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import SGDRegressor \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decay rate data set has three attributes (<b>pressure, temperature, rate-of-decay)</b>.  The objective is to predict rate-of-decay based on values of pressure and temperature.  \n",
    "\n",
    "Let's first retrieve the data and extract <b>X</b> and <b>y</b> from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv(\"decay_rate.csv\")\n",
    "X = np.array(data_set.drop([\"rate-of-decay\"], axis = 1))\n",
    "y = np.array(data_set[[\"rate-of-decay\"]])\n",
    "\n",
    "print(\"Shape of X: \\t\", X.shape)\n",
    "print(\"Shape of y: \\t\", y.shape)\n",
    "print(X[0,:])\n",
    "print(y[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "Shape of X: \t (1000, 2)\n",
    "\n",
    "Shape of y: \t (1000, 1)\n",
    "\n",
    "[ 4.09839746  6.5585182 ]\n",
    "\n",
    "[ 0.30537107]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's normalize X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE STARTS HERE\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "normalized_X = scaler.transform(X)\n",
    "\n",
    "#YOUR CODE ENDS HERE\n",
    "print(\"Shape of Normalized X:\\t\", normalized_X.shape)\n",
    "print(normalized_X[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "Shape of Normalized X:\t (1000, 2)\n",
    "\n",
    "[-0.29391077 -1.53446589]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have preprocessed X, it is time to put aside a test set.  Use train_test_split function to generate X_train, X_test, y_train, y_test.  You must make sure that the data is shuffled prior to split. Set the random seed to 3 for shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size = 0.1, random_state = 3)\n",
    "print(\"Shape of X_train: \\t\", X_train.shape)\n",
    "print(\"Shape of y_train: \\t\", y_train.shape)\n",
    "print(\"Shape of X_test: \\t\", X_test.shape)\n",
    "print(\"Shape of y_test: \\t\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "Shape of X_train: \t (900, 2)\n",
    "\n",
    "Shape of y_train: \t (900, 1)\n",
    "\n",
    "Shape of X_test: \t (100, 2)\n",
    "\n",
    "Shape of y_test: \t (100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to now extract a validation set from the training set.  Use the train_test_split method to break the training set into a new training set and a validation set.  Validation set should be 20% of the original training set.  Since X_train is already shuffled, in the interest of efficiency, now let's make sure no further shuffling will take place.  We will maintain the full train_set in new variable X_train_val_combined and y_train_val_combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val_combined = X_train\n",
    "y_train_val_combined = y_train\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, shuffle = False)\n",
    "print(\"Shape of X_train: \\t\", X_train.shape)\n",
    "print(\"Shape of X_val: \\t\", X_val.shape)\n",
    "print(\"Shape of y_train: \\t\", y_train.shape)\n",
    "print(\"Shape of y_val: \\t\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "Shape of X_train: \t (720, 2)\n",
    "\n",
    "Shape of X_val: \t (180, 2)\n",
    "\n",
    "Shape of y_train: \t (720, 1)\n",
    "\n",
    "Shape of y_val: \t (180, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a linear regression model using Stochastic Gradient Descent experiment with different learning rates (Use a random seed of 1 for model construction).  Write a for loop that would train an SGDRegressor using Max_iter of 1000 and learning rates of 0.0001, 0.001, 0.01, 0.1, 1, and 10.  The code should produce the learning rate used, the MSE on training and MSE on validation for each learning rate.  The code should also maintain these errors so that they can be plotted once the loop is done.  Feel Free to experiment with other learning rates, but please only report for the specified learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 1000\n",
    "MSE_train = []\n",
    "MSE_val = []\n",
    "for learning_rate in [0.0001, 0.001, 0.01, 0.1, 1, 10]:\n",
    "    linear_regression_model = SGDRegressor(max_iter = max_iterations, random_state = 1, eta0 = learning_rate)\n",
    "    linear_regression_model.fit(X_train, y_train)\n",
    "    h_train =\n",
    "    h_val =\n",
    "    mse_train =\n",
    "    MSE_train.append(mse_train)\n",
    "    mse_val =\n",
    "    MSE_val.append(mse_val)\n",
    "    print(\"lr: {0}; MSE_train: {1:.4f}, MSE_val: {2:.4f}\\n\".format(learning_rate, mse_train, mse_val))\n",
    "\n",
    "plt.plot(MSE_train, label=\"train MSE\")\n",
    "plt.plot(MSE_val, 'r', label=\"validation MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "<img src=\"Figure1.png\" width=\"40%\" height=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the best learning rate from the experiment you ran in the last step.  Use this learning rate to train a linear regression model with Stochastic Gradient Descent on the data that is composed of all samples from the training set and  validation set combined.  Use a random seed of 1 for model construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = \n",
    "linear_regression_model = \n",
    "linear_regression_model.fit(, )\n",
    "h_test = \n",
    "print(mean_squared_error(y_test, h_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "0.0102556838767"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the resulting MSE is good, let's see if we could do better.  Produce the learning curves for the model. Use a random seed of 1 for model construction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def plot_learning_curves(model, X_train, y_train, X_val, y_val):\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(5, len(X_train)):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        h_train = model.predict(X_train[:m])\n",
    "        h_val = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train[:m], h_train[:m]))\n",
    "        val_errors.append(mean_squared_error(y_val, h_val))\n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"Training Set\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"Validation Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_model = \n",
    "plot_learning_curves(, , , , )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "<img src=\"Figure2.png\" width=\"40%\" height=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see that the training and validation MSE converge very quickly and then remains steady.  This indicate a possible bias issue.  Let's see if the error improves if we can make the model more flexible.  Train the model using a polynomial of degree 30 and measure the performance.\n",
    "\n",
    "Lets start with the original data set X and y and preprocess using the following steps :\n",
    "\n",
    "a) Generate the polynomial features and assign the results in X_poly.\n",
    "\n",
    "b) Normalize the new data using StandardScaler\n",
    "\n",
    "c) Split X and y to train, test and validation as we did earlier. Set the random seed to 2 for shuffling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step a: Generate the polynomial features and assign the results in X_poly\n",
    "poly_features = \n",
    "X_poly = \n",
    "print(\"Shape of X_poly: \\t\", X_poly.shape)\n",
    "\n",
    "#Step b: Normalize\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_poly)\n",
    "normalized_X_poly = scaler.transform(X_poly)\n",
    "print(\"Shape of Normalized X:\\t\", normalized_X_poly.shape)\n",
    "\n",
    "#Step C: Generate train, test and validation sets\n",
    "X_train_poly, X_test_poly, y_train, y_test = \n",
    "print(\"Shape of X_train_poly: \\t\", X_train_poly.shape)\n",
    "print(\"Shape of y_train: \\t\", y_train.shape)\n",
    "print(\"Shape of X_test_poly: \\t\", X_test_poly.shape)\n",
    "print(\"Shape of y_test: \\t\", y_test.shape)\n",
    "\n",
    "X_train_val_poly_combined = X_train_poly\n",
    "y_train_val_combined = y_train\n",
    "X_train_poly, X_val_poly, y_train, y_val = \n",
    "print(\"Shape of X_train: \\t\", X_train_poly.shape)\n",
    "print(\"Shape of X_val: \\t\", X_val_poly.shape)\n",
    "print(\"Shape of y_train: \\t\", y_train.shape)\n",
    "print(\"Shape of y_val: \\t\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "Shape of X_poly: \t (1000, 495)\n",
    "\n",
    "Shape of Normalized X:\t (1000, 495)\n",
    "\n",
    "Shape of X_train_poly: \t (900, 495)\n",
    "\n",
    "Shape of y_train: \t (900, 1)\n",
    "\n",
    "Shape of X_test_poly: \t (100, 495)\n",
    "\n",
    "Shape of y_test: \t (100, 1)\n",
    "\n",
    "Shape of X_train: \t (720, 495)\n",
    "\n",
    "Shape of X_val: \t (180, 495)\n",
    "\n",
    "Shape of y_train: \t (720, 1)\n",
    "\n",
    "Shape of y_val: \t (180, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a linear regression model using Stochastic Gradient Descent experiment with different learning rates on the new data set.  Write a for loop that would train an SGDRegressor using Max_iter of 1000 and learning rates of 0.00001, 0.00003, 0.0001, 0.0003, 0.001.  The code should produce the learning rate used, the MSE on training and MSE on validation for each learning rate.  The code should also maintain these errors so that they can be plotted once the loop is done.  Feel Free to experiment with other learning rates, but please only report for the specified learning rates. Use a random seed of 1 for model construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 1000\n",
    "MSE_train = []\n",
    "MSE_val = []\n",
    "for learning_rate in [0.00001, 0.00003, 0.0001, 0.0003, 0.001]:\n",
    "    poly_regression_model = \n",
    "    poly_regression_model.fit(, )\n",
    "    h_train = \n",
    "    h_val = \n",
    "    mse_train = \n",
    "    MSE_train.append(mse_train)\n",
    "    mse_val = \n",
    "    MSE_val.append(mse_val)\n",
    "    print(\"lr: {0}; MSE_train: {1:.4f}, MSE_val: {2:.4f}\\n\".format(learning_rate, mse_train, mse_val))\n",
    "\n",
    "plt.plot(MSE_train, label=\"train MSE\")\n",
    "plt.plot(MSE_val, 'r', label=\"validation MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "<img src=\"Figure3.png\" width=\"40%\" height=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the best learning rate from the experiment you ran in the last step.  Use this learning rate to train a linear regression model with Stochastic Gradient Descent on the data that is composed of all samples from the training set and validation set combined. Use a random seed of 1 for model construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = \n",
    "ploy_regression_model = \n",
    "ploy_regression_model.fit(, )\n",
    "h_test = \n",
    "print(mean_squared_error(y_test, h_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "0.00313735829305"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting MSE is much better now, let's see if we could do even better.  Produce the learning curves for the polynomial model.  Use a random seed of 1 for model construction. \n",
    "\n",
    "This may take a while to run, so move on to something else and come back in about 1/2 hour.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploy_regression_model = \n",
    "plot_learning_curves(, , , , )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "<img src=\"Figure4.png\" width=\"40%\" height=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see improvement in MSE.  You should also observe that the training and validation MSE converge over time and that the validation error improves somewhat as new training samples are added.  This indicate a possible variance issue.  Let's see if the error improves if we make the model less flexible through regularization.  \n",
    "\n",
    "Train ridge regression model on the same poly datasets.  Use the best learning rate discovered in your poly experiment.   Write a for loop to experiment with regularization parameters of 0.0001, 0.001, 0.01, 0.1, 0.2. The code should produce the regularization value that was used, the MSE on training and MSE on validation for each regularization value. Feel Free to experiment with other regularization values, but please only report for the specified values. Use a random seed of 1 for model construction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train = []\n",
    "MSE_val = []\n",
    "for regularization_param in [0.0001, 0.001, 0.01, 0.1, 0.2]:\n",
    "    ridge_regression_model = \n",
    "    ridge_regression_model.fit(, )\n",
    "    h_train = ridge_regression_model.predict()\n",
    "    h_val = ridge_regression_model.predict()\n",
    "    mse_train = mean_squared_error(, )\n",
    "    MSE_train.append(mse_train)\n",
    "    mse_val = mean_squared_error(, )\n",
    "    MSE_val.append(mse_val)\n",
    "    print(\"alpha: {0}, MSE_train: {1:.4f}, MSE_val: {2:.4f}\\n\".format(regularization_param, mse_train, mse_val))\n",
    "\n",
    "plt.plot(MSE_train, label=\"train MSE\")\n",
    "plt.plot(MSE_val, 'r', label=\"validation MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "<img src=\"Figure5.png\" width=\"40%\" height=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Identify the best regularization parameters from the experiment you ran in the last step.  Use this learning rate to train a ridge regression model with Stochastic Gradient Descent on the data that is composed of all samples from the training set and validation set combined. Use a random seed of 1 for model construction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_alpha = 0.001\n",
    "ridge_regression_model = \n",
    "ridge_regression_model.fit(, )\n",
    "h_test = ridge_regression_model.predict()\n",
    "print(mean_squared_error(y_test, h_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output\n",
    "0.0031429175403844727"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did regularization help?  Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
